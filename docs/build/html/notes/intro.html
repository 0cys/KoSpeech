

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Intro &mdash; End-to-end Speech Recognition 2.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Preparation before Training" href="Preparation.html" />
    <link rel="prev" title="Welcome to End-to-end Speech Recognition’s documentation!" href="../index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> End-to-end Speech Recognition
          

          
          </a>

          
            
            
              <div class="version">
                2.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">NOTES</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Intro</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#crr-character-recognition-rate">( <strong>CRR</strong> : Character Recognition Rate )</a></li>
<li class="toctree-l2"><a class="reference internal" href="#features">Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="#roadmap">Roadmap</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#e2e-module">e2e module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="#install-from-source">Install from source</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#get-started">Get Started</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#step-1-preparation-dataset">Step 1: Preparation dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-run-train-py">Step 2: Run <code class="docutils literal notranslate"><span class="pre">train.py</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-3-run-infer-py">Step 3: Run <code class="docutils literal notranslate"><span class="pre">infer.py</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="#checkpoints">Checkpoints</a></li>
<li class="toctree-l3"><a class="reference internal" href="#incorporating-external-language-model-in-performance-test">Incorporating External Language Model in Performance Test</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#troubleshoots-and-contributing">Troubleshoots and Contributing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#code-style">Code Style</a></li>
<li class="toctree-l3"><a class="reference internal" href="#reference">Reference</a></li>
<li class="toctree-l3"><a class="reference internal" href="#citing">Citing</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="Preparation.html">Preparation before Training</a></li>
<li class="toctree-l1"><a class="reference internal" href="opts.html">Options</a></li>
</ul>
<p class="caption"><span class="caption-text">ARCHITECTURE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Model.html">Model</a></li>
</ul>
<p class="caption"><span class="caption-text">PACKAGE REFERENCE</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Data_loader.html">Data_loader</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Evaluator.html">Evaluator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Feature.html">Feature</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Loss.html">Loss</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Optim.html">Optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Trainer.html">Trainer</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">End-to-end Speech Recognition</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>Intro</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/notes/intro.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="intro">
<h1>Intro<a class="headerlink" href="#intro" title="Permalink to this headline">¶</a></h1>
<p>This is project for End-to-end Speech Recognition using LAS (Listen, Attend and Spell) models implemented in <a class="reference external" href="http://pytorch.org">PyTorch</a>.<br />This repository has modularized and extensible components for las models, training and inference, checkpoints etc.<br />We appreciate any kind of <a class="reference external" href="https://github.com/sooftware/End-to-end-Speech-Recognition/issues">feedback or contribution</a>.</p>
<p>We used <a class="reference external" href="http://www.aihub.or.kr/aidata/105">KsponSpeech</a> corpus which containing <strong>1000h</strong> of Korean speech data.<br />At present our model has recorded an <strong>86.78% CRR</strong>, and we are working for a higher recognition rate.<br />Also our model has recorded <strong>91.0% CRR</strong> in <a class="reference external" href="https://github.com/goodatlas/zeroth">Kadi-zeroth dataset</a>.</p>
<div class="section" id="crr-character-recognition-rate">
<h2>( <strong>CRR</strong> : Character Recognition Rate )<a class="headerlink" href="#crr-character-recognition-rate" title="Permalink to this headline">¶</a></h2>
<img src="https://user-images.githubusercontent.com/42150335/80630547-5dfc6580-8a8f-11ea-91e8-73fe5e8b9e4b.png" width=450> </div>
<div class="section" id="features">
<h2>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/">End-to-end (E2E) automatic speech recognition</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Model.html#module-e2e.model.listener">Convolutional encoder</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Model.html#module-e2e.model.listener">MaskConv &amp; pack_padded_sequence</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Model.html#module-e2e.model.attention">Multi-Head Attention</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Model.html#module-e2e.model.topk_decoder">Top K Decoding (Beam Search)</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Feature.html#module-e2e.feature.parser">Spectrogram Parser</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Feature.html#module-e2e.feature.parser">Delete silence</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Feature.html#module-e2e.feature.parser">SpecAugment</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Feature.html#module-e2e.feature.parser">NoiseAugment</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Loss.html">Label Smoothing</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Modules.html#module-e2e.modules.checkpoint">Save &amp; load Checkpoint</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Modules.html#module-e2e.modules.opts">Various options can be set using parser</a></li>
<li><a class="reference external" href="https://sooftware.github.io/End-to-end-Speech-Recognition/Data_loader.html#id1">Implement data loader as multi-thread for speed</a></li>
<li>Inference with batching</li>
<li>Multi-GPU training</li>
<li>Show training states as log</li>
</ul>
</div>
<div class="section" id="roadmap">
<h2>Roadmap<a class="headerlink" href="#roadmap" title="Permalink to this headline">¶</a></h2>
<p>End-to-end (E2E) automatic speech recognition (ASR) is an emerging paradigm in the field of neural network-based speech recognition that offers multiple benefits. Traditional “hybrid” ASR systems, which are comprised of an acoustic model, language model, and pronunciation model, require separate training of these components, each of which can be complex.</p>
<p>For example, training of an acoustic model is a multi-stage process of model training and time alignment between the speech acoustic feature sequence and output label sequence. In contrast, E2E ASR is a single integrated approach with a much simpler training pipeline with models that operate at low audio frame rates. This reduces the training time, decoding time, and allows joint optimization with downstream processing such as natural language understanding.</p>
<p>We mainly referred to following papers.</p>
<p><a class="reference external" href="https://arxiv.org/abs/1508.01211">「Listen, Attend and Spell」</a></p>
<p><a class="reference external" href="https://arxiv.org/abs/1712.01769">「State-of-the-art Speech Recognition with Sequence-to-Sequence Models」</a></p>
<p><a class="reference external" href="https://arxiv.org/abs/1904.08779">「SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition」</a>.</p>
<p>If you want to study the feature of audio, we recommend this papers.</p>
<p><a class="reference external" href="https://ijirae.com/volumes/vol1/issue10/27.NVEC10086.pdf">「Voice Recognition Using MFCC Algirithm」</a>.</p>
<p>Our project based on Seq2seq with Attention Architecture.</p>
<p>Sequence to sequence architecture is a field that is still actively studied in the field of speech recognition.<br />Our model architeuture is as follows.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ListenAttendSpell</span><span class="p">(</span>
  <span class="p">(</span><span class="n">listener</span><span class="p">):</span> <span class="n">Listener</span><span class="p">(</span>
    <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">GRU</span><span class="p">(</span><span class="mi">2560</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">bidirectional</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="n">cnn</span><span class="p">):</span> <span class="n">MaskCNN</span><span class="p">(</span>
      <span class="p">(</span><span class="n">sequential</span><span class="p">):</span> <span class="n">Sequential</span><span class="p">(</span>
        <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="n">Hardtanh</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="n">Hardtanh</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="n">Hardtanh</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">9</span><span class="p">):</span> <span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">track_running_stats</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="n">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="n">Hardtanh</span><span class="p">(</span><span class="n">min_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_val</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="p">(</span><span class="mi">12</span><span class="p">):</span> <span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">)</span>
    <span class="p">)</span>
  <span class="p">)</span>
  <span class="p">(</span><span class="n">speller</span><span class="p">):</span> <span class="n">Speller</span><span class="p">(</span>
    <span class="p">(</span><span class="n">rnn</span><span class="p">):</span> <span class="n">GRU</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">num_layers</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="p">(</span><span class="n">embedding</span><span class="p">):</span> <span class="n">Embedding</span><span class="p">(</span><span class="mi">2038</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>
    <span class="p">(</span><span class="n">input_dropout</span><span class="p">):</span> <span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="n">attention</span><span class="p">):</span> <span class="n">MultiHybridAttention</span><span class="p">(</span>
      <span class="p">(</span><span class="n">scaled_dot</span><span class="p">):</span> <span class="n">ScaledDotProductAttention</span><span class="p">()</span>
      <span class="p">(</span><span class="n">conv1d</span><span class="p">):</span> <span class="n">Conv1d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,))</span>
      <span class="p">(</span><span class="n">linear_q</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">linear_v</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">linear_u</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
      <span class="p">(</span><span class="n">linear_out</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
      <span class="p">(</span><span class="n">normalize</span><span class="p">):</span> <span class="n">LayerNorm</span><span class="p">((</span><span class="mi">512</span><span class="p">,),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-05</span><span class="p">,</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="p">(</span><span class="n">linear_out</span><span class="p">):</span> <span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">2038</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="section" id="e2e-module">
<h3>e2e module<a class="headerlink" href="#e2e-module" title="Permalink to this headline">¶</a></h3>
<img src="https://user-images.githubusercontent.com/42150335/82733873-f960bd80-9d51-11ea-83ec-658ed0f90142.png" width=800>   <p>Our e2e (End-to-end) module’s structure is implement as above.<br />e2e module has modularized and extensible components for las models, trainer, evaluator, checkpoints, data_loader etc…</p>
<p>We are constantly updating the progress of the project on the <a class="reference external" href="https://github.com/sooftware/End-to-end-Speech-Recognition/wiki">Wiki page</a>.  Please check this page.</p>
</div>
</div>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>This project recommends Python 3.7 or higher.<br />We recommend creating a new virtual environment for this project (using virtual env or conda).</p>
<div class="section" id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Numpy: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">numpy</span></code> (Refer <a class="reference external" href="https://github.com/numpy/numpy">here</a> for problem installing Numpy).</li>
<li>Pytorch: Refer to <a class="reference external" href="http://pytorch.org/">PyTorch website</a> to install the version w.r.t. your environment.</li>
<li>Pandas: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">pandas</span></code> (Refer <a class="reference external" href="https://github.com/pandas-dev/pandas">here</a> for problem installing Pandas)</li>
<li>librosa: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">librosa</span></code> (Refer <a class="reference external" href="https://github.com/librosa/librosa">here</a> for problem installing librosa)</li>
<li>torchaudio: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">torchaudio</span></code> (Refer <a class="reference external" href="https://github.com/pytorch/pytorch">here</a> for problem installing torchaudio)</li>
<li>tqdm: <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">tqdm</span></code> (Refer <a class="reference external" href="https://github.com/tqdm/tqdm">here</a> for problem installing tqdm)</li>
</ul>
</div>
<div class="section" id="install-from-source">
<h3>Install from source<a class="headerlink" href="#install-from-source" title="Permalink to this headline">¶</a></h3>
<p>Currently we only support installation from source code using setuptools. Checkout the source code and run the<br />following commands:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="o">.</span><span class="n">txt</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">build</span>
<span class="n">python</span> <span class="n">setup</span><span class="o">.</span><span class="n">py</span> <span class="n">install</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="get-started">
<h2>Get Started<a class="headerlink" href="#get-started" title="Permalink to this headline">¶</a></h2>
<div class="section" id="step-1-preparation-dataset">
<h3>Step 1: Preparation dataset<a class="headerlink" href="#step-1-preparation-dataset" title="Permalink to this headline">¶</a></h3>
<p>Refer <a class="reference external" href="https://github.com/sooftware/End-to-end-Speech-Recognition/wiki/Preparation-before-Training">here</a> before training. this document contains information regarding the preprocessing of <a class="reference external" href="http://www.aihub.or.kr/aidata/105">KsponSpeech</a>.<br />The above document is written in Korean.<br />We will also write a document in English as soon as possible, so please wait a little bit.</p>
</div>
<div class="section" id="step-2-run-train-py">
<h3>Step 2: Run <code class="docutils literal notranslate"><span class="pre">train.py</span></code><a class="headerlink" href="#step-2-run-train-py" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Default setting</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./train.sh
</pre></div>
</div>
<ul class="simple">
<li>Custom setting</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">./</span><span class="n">train</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">dataset_path</span> <span class="o">/</span><span class="n">data1</span><span class="o">/</span> <span class="o">-</span><span class="n">data_list_path</span> <span class="o">./</span><span class="n">data</span><span class="o">/</span><span class="n">data_list</span><span class="o">/</span><span class="n">filter_train_list</span><span class="o">.</span><span class="n">csv</span> \
                  <span class="o">-</span><span class="n">use_multi_gpu</span> <span class="o">-</span><span class="n">init_uniform</span> <span class="o">-</span><span class="n">mode</span> <span class="n">train</span> <span class="o">-</span><span class="n">batch_size</span> <span class="mi">32</span> <span class="o">-</span><span class="n">num_workers</span> <span class="mi">4</span> \
                  <span class="o">-</span><span class="n">num_epochs</span> <span class="mi">20</span> <span class="o">-</span><span class="n">spec_augment</span> <span class="o">-</span><span class="n">noise_augment</span> <span class="o">-</span><span class="n">max_len</span> <span class="mi">151</span> \
                  <span class="o">-</span><span class="n">use_cuda</span> <span class="o">-</span><span class="n">lr</span> <span class="mf">3e-04</span> <span class="o">-</span><span class="n">min_lr</span> <span class="mf">1e-05</span> <span class="o">-</span><span class="n">lr_patience</span> <span class="mi">1</span><span class="o">/</span><span class="mi">3</span> <span class="o">-</span><span class="n">valid_ratio</span> <span class="mf">0.01</span> \
                  <span class="o">-</span><span class="n">label_smoothing</span> <span class="mf">0.1</span> <span class="o">-</span><span class="n">save_result_every</span> <span class="mi">1000</span> <span class="o">-</span><span class="n">print_every</span> <span class="mi">10</span> <span class="o">-</span><span class="n">checkpoint_every</span> <span class="mi">5000</span> \
                  <span class="o">-</span><span class="n">use_bidirectional</span> <span class="o">-</span><span class="n">hidden_dim</span> <span class="mi">256</span> <span class="o">-</span><span class="n">dropout</span> <span class="mf">0.3</span> <span class="o">-</span><span class="n">num_heads</span> <span class="mi">8</span> <span class="o">-</span><span class="n">rnn_type</span> <span class="n">gru</span> \
                  <span class="o">-</span><span class="n">listener_layer_size</span> <span class="mi">5</span> <span class="o">-</span><span class="n">speller_layer_size</span> <span class="mi">3</span> <span class="o">-</span><span class="n">teacher_forcing_ratio</span> <span class="mf">0.99</span> \ 
                  <span class="o">-</span><span class="n">input_reverse</span> <span class="o">-</span><span class="n">normalize</span> <span class="o">-</span><span class="n">del_silence</span> <span class="o">-</span><span class="n">sample_rate</span> <span class="mi">16000</span> <span class="o">-</span><span class="n">window_size</span> <span class="mi">20</span> <span class="o">-</span><span class="n">stride</span> <span class="mi">10</span> <span class="o">-</span><span class="n">n_mels</span> <span class="mi">80</span> \
                  <span class="o">-</span><span class="n">feature_extract_by</span> <span class="n">librosa</span> <span class="o">-</span><span class="n">time_mask_para</span> <span class="mi">50</span> <span class="o">-</span><span class="n">freq_mask_para</span> <span class="mi">12</span> \
                  <span class="o">-</span><span class="n">time_mask_num</span> <span class="mi">2</span> <span class="o">-</span><span class="n">freq_mask_num</span> <span class="mi">2</span>
</pre></div>
</div>
<p>You can train the model by above command.<br />If you want to train by default setting, you can train by <code class="docutils literal notranslate"><span class="pre">Defaulting</span> <span class="pre">setting</span></code> command.<br />Or if you want to train by custom setting, you can designate hyperparameters by <code class="docutils literal notranslate"><span class="pre">Custom</span> <span class="pre">setting</span></code> command.</p>
</div>
<div class="section" id="step-3-run-infer-py">
<h3>Step 3: Run <code class="docutils literal notranslate"><span class="pre">infer.py</span></code><a class="headerlink" href="#step-3-run-infer-py" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li>Default setting</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ./infer.sh
</pre></div>
</div>
<ul class="simple">
<li>Custom setting</li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">./</span><span class="n">infer</span><span class="o">.</span><span class="n">py</span> <span class="o">-</span><span class="n">dataset_path</span> <span class="o">/</span><span class="n">data1</span><span class="o">/</span> <span class="o">-</span><span class="n">data_list_path</span> <span class="o">./</span><span class="n">data</span><span class="o">/</span><span class="n">data_list</span><span class="o">/</span><span class="n">filter_test_list</span><span class="o">.</span><span class="n">csv</span> \
                  <span class="o">-</span><span class="n">mode</span> <span class="n">infer</span> <span class="o">-</span><span class="n">use_multi_gpu</span> <span class="o">-</span><span class="n">use_cuda</span> <span class="o">-</span><span class="n">batch_size</span> <span class="mi">32</span> <span class="o">-</span><span class="n">num_workers</span> <span class="mi">4</span> \
                  <span class="o">-</span><span class="n">use_beam_search</span> <span class="o">-</span><span class="n">k</span> <span class="mi">5</span> <span class="o">-</span><span class="n">print_every</span> <span class="mi">100</span> \
                  <span class="o">-</span><span class="n">sample_rate</span> <span class="mi">16000</span> <span class="o">--</span><span class="n">window_size</span> <span class="mi">20</span> <span class="o">--</span><span class="n">stride</span> <span class="mi">10</span> <span class="o">--</span><span class="n">n_mels</span> <span class="mi">80</span> <span class="o">-</span><span class="n">feature_extract_by</span> <span class="n">librosa</span> \
                  <span class="o">-</span><span class="n">normalize</span> <span class="o">-</span><span class="n">del_silence</span> <span class="o">-</span><span class="n">input_reverse</span> 
</pre></div>
</div>
<p>Now you have a model which you can use to predict on new data. We do this by running beam search (or greedy search).<br />Like training, you can choose between <code class="docutils literal notranslate"><span class="pre">Default</span> <span class="pre">setting</span></code> or <code class="docutils literal notranslate"><span class="pre">Custom</span> <span class="pre">setting</span></code>.</p>
</div>
<div class="section" id="checkpoints">
<h3>Checkpoints<a class="headerlink" href="#checkpoints" title="Permalink to this headline">¶</a></h3>
<p>Checkpoints are organized by experiments and timestamps as shown in the following file structure.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">save_dir</span>
<span class="o">+--</span> <span class="n">checkpoints</span>
<span class="o">|</span>  <span class="o">+--</span> <span class="n">YYYY_mm_dd_HH_MM_SS</span>
   <span class="o">|</span>  <span class="o">+--</span> <span class="n">trainer_states</span><span class="o">.</span><span class="n">pt</span>
   <span class="o">|</span>  <span class="o">+--</span> <span class="n">model</span><span class="o">.</span><span class="n">pt</span>
</pre></div>
</div>
<p>You can resume and load from checkpoints.</p>
</div>
<div class="section" id="incorporating-external-language-model-in-performance-test">
<h3>Incorporating External Language Model in Performance Test<a class="headerlink" href="#incorporating-external-language-model-in-performance-test" title="Permalink to this headline">¶</a></h3>
<p>We introduce incorporating external language model in performance test.<br />If you are interested in this content, please check <a class="reference external" href="https://github.com/sooftware/char-rnnlm">here</a>.</p>
</div>
</div>
<div class="section" id="troubleshoots-and-contributing">
<h2>Troubleshoots and Contributing<a class="headerlink" href="#troubleshoots-and-contributing" title="Permalink to this headline">¶</a></h2>
<p>If you have any questions, bug reports, and feature requests, please <a class="reference external" href="https://github.com/sooftware/End-to-end-Speech-Recognition/issues">open an issue</a> on Github.<br />For live discussions, please go to our <a class="reference external" href="https://gitter.im/Korean-Speech-Recognition/community">gitter</a> or Contacts sh951011&#64;gmail.com please.</p>
<p>We appreciate any kind of feedback or contribution.  Feel free to proceed with small issues like bug fixes, documentation improvement.  For major contributions and new features, please discuss with the collaborators in corresponding issues.</p>
<div class="section" id="code-style">
<h3>Code Style<a class="headerlink" href="#code-style" title="Permalink to this headline">¶</a></h3>
<p>We follow <a class="reference external" href="https://www.python.org/dev/peps/pep-0008/">PEP-8</a> for code style. Especially the style of docstrings is important to generate documentation.</p>
</div>
<div class="section" id="reference">
<h3>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="https://arxiv.org/abs/1508.01211">[1] 「Listen, Attend and Spell」  Paper</a><br /><a class="reference external" href="https://arxiv.org/abs/1712.01769">[2] 「State-of-the-art Speech Recognition with Sequence-to-Sequence Models」   Paper</a><br /><a class="reference external" href="https://arxiv.org/abs/1904.08779">[3] 「A Simple Data Augmentation Method for Automatic Speech Recognition」  Paper</a><br /><a class="reference external" href="https://arxiv.org/abs/1712.01996">[4] 「An analysis of incorporating an external language model into a sequence-to-sequence model」  Paper</a><br /><a class="reference external" href="https://ijirae.com/volumes/vol1/issue10/27.NVEC10086.pdf">[5] 「Voice Recognition Using MFCC Algorithm」  Paper</a><br /><a class="reference external" href="https://github.com/IBM/pytorch-seq2seq">[6] 「IBM pytorch-seq2seq」</a><br /><a class="reference external" href="https://github.com/SeanNaren/deepspeech.pytorch">[7] 「SeanNaren deepspeech.pytorch」</a><br /><a class="reference external" href="https://github.com/sooftware/char-rnnlm">[8] 「Character RNN Language Model」</a><br /><a class="reference external" href="http://www.aihub.or.kr/aidata/105">[9] 「KsponSpeech」</a><br /><a class="reference external" href="https://sooftware.github.io/End-to-End-Korean-Speech-Recognition/">[10] 「Documentation」</a></p>
</div>
<div class="section" id="citing">
<h3>Citing<a class="headerlink" href="#citing" title="Permalink to this headline">¶</a></h3>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nd">@github</span><span class="p">{</span>
  <span class="n">title</span> <span class="o">=</span> <span class="p">{</span><span class="n">End</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">end</span> <span class="n">Speech</span> <span class="n">Recognition</span><span class="p">},</span>
  <span class="n">author</span> <span class="o">=</span> <span class="p">{</span><span class="n">Soohwan</span> <span class="n">Kim</span><span class="p">,</span> <span class="n">Seyoung</span> <span class="n">Bae</span><span class="p">,</span> <span class="n">Cheolhwang</span> <span class="n">Won</span><span class="p">},</span>
  <span class="n">publisher</span> <span class="o">=</span> <span class="p">{</span><span class="n">GitHub</span><span class="p">},</span>
  <span class="n">docs</span> <span class="o">=</span> <span class="p">{</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">sooftware</span><span class="o">.</span><span class="n">github</span><span class="o">.</span><span class="n">io</span><span class="o">/</span><span class="n">End</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">end</span><span class="o">-</span><span class="n">Speech</span><span class="o">-</span><span class="n">Recognition</span><span class="o">/</span><span class="p">},</span>
  <span class="n">url</span> <span class="o">=</span> <span class="p">{</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">sooftware</span><span class="o">/</span><span class="n">End</span><span class="o">-</span><span class="n">to</span><span class="o">-</span><span class="n">end</span><span class="o">-</span><span class="n">Speech</span><span class="o">-</span><span class="n">Recognition</span><span class="p">},</span>
  <span class="n">year</span> <span class="o">=</span> <span class="p">{</span><span class="mi">2020</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Preparation.html" class="btn btn-neutral float-right" title="Preparation before Training" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../index.html" class="btn btn-neutral float-left" title="Welcome to End-to-end Speech Recognition’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Soohwan Kim

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>