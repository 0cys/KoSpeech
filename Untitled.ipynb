{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-02-23 23:28:01,309 hparams.py:71 - logger_hparams()] use_bidirectional : True\n",
      "[2020-02-23 23:28:01,311 hparams.py:72 - logger_hparams()] use_attention : True\n",
      "[2020-02-23 23:28:01,312 hparams.py:73 - logger_hparams()] use_pickle : True\n",
      "[2020-02-23 23:28:01,314 hparams.py:74 - logger_hparams()] use_augment : True\n",
      "[2020-02-23 23:28:01,316 hparams.py:75 - logger_hparams()] use_pyramidal : True\n",
      "[2020-02-23 23:28:01,319 hparams.py:76 - logger_hparams()] attention : dot-product\n",
      "[2020-02-23 23:28:01,321 hparams.py:77 - logger_hparams()] augment_ratio : 1.00\n",
      "[2020-02-23 23:28:01,322 hparams.py:78 - logger_hparams()] input_reverse : True\n",
      "[2020-02-23 23:28:01,324 hparams.py:79 - logger_hparams()] hidden_size : 256\n",
      "[2020-02-23 23:28:01,326 hparams.py:80 - logger_hparams()] listener_layer_size : 6\n",
      "[2020-02-23 23:28:01,327 hparams.py:81 - logger_hparams()] speller_layer_size : 3\n",
      "[2020-02-23 23:28:01,329 hparams.py:82 - logger_hparams()] dropout : 0.50\n",
      "[2020-02-23 23:28:01,330 hparams.py:83 - logger_hparams()] batch_size : 6\n",
      "[2020-02-23 23:28:01,333 hparams.py:84 - logger_hparams()] worker_num : 1\n",
      "[2020-02-23 23:28:01,335 hparams.py:85 - logger_hparams()] max_epochs : 40\n",
      "[2020-02-23 23:28:01,337 hparams.py:86 - logger_hparams()] initial learning rate : 0.0001\n",
      "[2020-02-23 23:28:01,339 hparams.py:87 - logger_hparams()] high plateau learning rate : 0.0010\n",
      "[2020-02-23 23:28:01,340 hparams.py:88 - logger_hparams()] low plateau learning rate : 0.0000\n",
      "[2020-02-23 23:28:01,342 hparams.py:89 - logger_hparams()] teacher_forcing_ratio : 0.90\n",
      "[2020-02-23 23:28:01,343 hparams.py:90 - logger_hparams()] seed : 1\n",
      "[2020-02-23 23:28:01,345 hparams.py:91 - logger_hparams()] max_len : 120\n",
      "[2020-02-23 23:28:01,346 hparams.py:92 - logger_hparams()] use_cuda : True\n",
      "[2020-02-23 23:28:01,348 hparams.py:93 - logger_hparams()] save_name : model\n",
      "[2020-02-23 23:28:01,349 hparams.py:94 - logger_hparams()] mode : train\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "from utils.define import *\n",
    "from utils.dataset import split_dataset\n",
    "from utils.hparams import HyperParams\n",
    "from utils.loader import BaseDataLoader, MultiLoader\n",
    "from utils.load import load_targets, load_data_list, load_pickle\n",
    "from utils.save import save_epoch_result, save_pickle\n",
    "from utils.evaluator import evaluate\n",
    "from utils.trainer import train\n",
    "from models.speller import Speller\n",
    "from models.listener import Listener\n",
    "from models.listenAttendSpell import ListenAttendSpell\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "    #logger.info(\"device : %s\" % torch.cuda.get_device_name(0))\n",
    "    #logger.info(\"CUDA is available : %s\" % (torch.cuda.is_available()))\n",
    "    #logger.info(\"CUDA version : %s\" % (torch.version.cuda))\n",
    "    #logger.info(\"PyTorch version : %s\" % (torch.__version__))\n",
    "\n",
    "    hparams = HyperParams()\n",
    "    hparams.logger_hparams()\n",
    "\n",
    "    random.seed(hparams.seed)\n",
    "    torch.manual_seed(hparams.seed)\n",
    "    torch.cuda.manual_seed_all(hparams.seed)\n",
    "    cuda = hparams.use_cuda and torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if cuda else 'cpu')\n",
    "\n",
    "    feat_size = 33\n",
    "    listener = Listener(\n",
    "        feat_size = feat_size,\n",
    "        hidden_size = hparams.hidden_size,\n",
    "        dropout_p = hparams.dropout,\n",
    "        layer_size = hparams.listener_layer_size,\n",
    "        bidirectional = hparams.use_bidirectional,\n",
    "        rnn_cell = 'gru',\n",
    "        use_pyramidal = hparams.use_pyramidal\n",
    "    )\n",
    "    speller = Speller(\n",
    "        vocab_size = len(char2index),\n",
    "        max_len = hparams.max_len,\n",
    "        k = 8,\n",
    "        hidden_size = hparams.hidden_size << (1 if hparams.use_bidirectional else 0),\n",
    "        batch_size = hparams.batch_size,\n",
    "        sos_id = SOS_token,\n",
    "        eos_id = EOS_token,\n",
    "        layer_size = hparams.speller_layer_size,\n",
    "        score_function = hparams.score_function,\n",
    "        rnn_cell = 'gru',\n",
    "        dropout_p = hparams.dropout,\n",
    "        use_attention = hparams.use_attention,\n",
    "        device = device\n",
    "    )\n",
    "    model = ListenAttendSpell(\n",
    "        listener = listener,\n",
    "        speller = speller,\n",
    "        use_pyramidal = hparams.use_pyramidal\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListenAttendSpell(\n",
       "  (listener): Listener(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (14): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (bottom_rnn): GRU(2048, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    (middle_rnn): PyramidalRNN(\n",
       "      (rnn): GRU(1024, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    )\n",
       "    (top_rnn): PyramidalRNN(\n",
       "      (rnn): GRU(1024, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    )\n",
       "  )\n",
       "  (speller): Speller(\n",
       "    (rnn): GRU(512, 512, num_layers=3, batch_first=True, dropout=0.5)\n",
       "    (embedding): Embedding(2040, 512)\n",
       "    (input_dropout): Dropout(p=0.5, inplace=False)\n",
       "    (attention): Attention(\n",
       "      (attention): DotProductAttention(\n",
       "        (linear_out): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (out): Linear(in_features=512, out_features=2040, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
