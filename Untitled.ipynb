{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from models.speller import Speller\n",
    "from models.listener import Listener\n",
    "from models.listenAttendSpell import ListenAttendSpell\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "listener = Listener(feat_size=33, hidden_size=256,\n",
    "                        dropout_p=0.5, layer_size=5,\n",
    "                        bidirectional=True, rnn_cell='gru', use_pyramidal=True)\n",
    "\n",
    "speller = Speller(vocab_size=2040, max_len=80, k=8,\n",
    "                      hidden_size=256 * (2 if True else 1),\n",
    "                      sos_id=2037, eos_id=2038, layer_size = 3,\n",
    "                      rnn_cell = 'gru', dropout_p = 0.5, use_attention = True)\n",
    "\n",
    "model = ListenAttendSpell(listener=listener, speller=speller, use_pyramidal=True)\n",
    "model.flatten_parameters()\n",
    "model = nn.DataParallel(model).to(device)\n",
    "optimizer = optim.Adam(model.module.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(optimizer):\n",
    "    for g in optimizer.param_groups:\n",
    "            g['lr'] = 0.01\n",
    "            print(g['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n"
     ]
    }
   ],
   "source": [
    "test(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.01\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lr(optimizer):\n",
    "    \"\"\" 띠용 \"\"\"\n",
    "    for g in optimizer.param_groups:\n",
    "        return g['lr']\n",
    "get_lr(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_lr in module __main__:\n",
      "\n",
      "get_lr(optimizer)\n",
      "    띠용\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(get_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
