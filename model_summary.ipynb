{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-05-04 05:23:20,493 config.py:113 - print_log()] use_bidirectional : True\n",
      "[2020-05-04 05:23:20,495 config.py:114 - print_log()] use_pickle : False\n",
      "[2020-05-04 05:23:20,497 config.py:115 - print_log()] use_augment : True\n",
      "[2020-05-04 05:23:20,499 config.py:116 - print_log()] augment_num : 1\n",
      "[2020-05-04 05:23:20,500 config.py:117 - print_log()] input_reverse : True\n",
      "[2020-05-04 05:23:20,501 config.py:118 - print_log()] hidden_dim : 256\n",
      "[2020-05-04 05:23:20,503 config.py:119 - print_log()] listener_layer_size : 5\n",
      "[2020-05-04 05:23:20,505 config.py:120 - print_log()] speller_layer_size : 3\n",
      "[2020-05-04 05:23:20,506 config.py:121 - print_log()] rnn_type : gru\n",
      "[2020-05-04 05:23:20,507 config.py:122 - print_log()] num_head : 4\n",
      "[2020-05-04 05:23:20,509 config.py:123 - print_log()] attn_dim : 128\n",
      "[2020-05-04 05:23:20,510 config.py:124 - print_log()] dropout : 0.40\n",
      "[2020-05-04 05:23:20,512 config.py:125 - print_log()] batch_size : 32\n",
      "[2020-05-04 05:23:20,513 config.py:126 - print_log()] worker_num : 1\n",
      "[2020-05-04 05:23:20,515 config.py:127 - print_log()] max_epochs : 40\n",
      "[2020-05-04 05:23:20,516 config.py:128 - print_log()] valid_ratio : 0.010000\n",
      "[2020-05-04 05:23:20,519 config.py:129 - print_log()] initial learning rate : 0.0010\n",
      "[2020-05-04 05:23:20,521 config.py:130 - print_log()] teacher_forcing_ratio : 1.00\n",
      "[2020-05-04 05:23:20,522 config.py:131 - print_log()] seed : 1\n",
      "[2020-05-04 05:23:20,524 config.py:132 - print_log()] max_len : 151\n",
      "[2020-05-04 05:23:20,526 config.py:133 - print_log()] use_cuda : True\n",
      "[2020-05-04 05:23:20,527 config.py:134 - print_log()] n_mels : 80\n",
      "[2020-05-04 05:23:20,528 config.py:135 - print_log()] sr : 16000\n",
      "[2020-05-04 05:23:20,530 config.py:136 - print_log()] window_size : 20\n",
      "[2020-05-04 05:23:20,531 config.py:137 - print_log()] stride : 10\n",
      "[2020-05-04 05:23:20,532 config.py:138 - print_log()] del_silence : True\n",
      "[2020-05-04 05:23:20,534 config.py:139 - print_log()] normalize : True\n",
      "[2020-05-04 05:23:20,536 config.py:140 - print_log()] feature_extract_by : librosa\n",
      "[2020-05-04 05:23:20,538 config.py:141 - print_log()] time_mask_para : 40\n",
      "[2020-05-04 05:23:20,540 config.py:142 - print_log()] freq_mask_para : 10\n",
      "[2020-05-04 05:23:20,542 config.py:143 - print_log()] time_mask_num : 2\n",
      "[2020-05-04 05:23:20,544 config.py:144 - print_log()] freq_mask_num : 2\n"
     ]
    }
   ],
   "source": [
    "from torchsummaryX import summary\n",
    "import torch\n",
    "from utils.config import Config\n",
    "from model.speller import Speller\n",
    "from model.listener import Listener\n",
    "from model.listenAttendSpell import ListenAttendSpell\n",
    "\n",
    "config = Config(\n",
    "    use_bidirectional=True,\n",
    "    input_reverse=True,\n",
    "    use_augment=True,\n",
    "    use_pickle=False,\n",
    "    use_cuda=True,\n",
    "    augment_num=1,\n",
    "    hidden_dim=256,\n",
    "    dropout=0.4,\n",
    "    num_head=4,\n",
    "    attn_dim=128,\n",
    "    label_smoothing=0.1,\n",
    "    listener_layer_size=5,\n",
    "    speller_layer_size=3,\n",
    "    batch_size=32,\n",
    "    worker_num=1,\n",
    "    max_epochs=40,\n",
    "    lr=0.001,\n",
    "    teacher_forcing_ratio=1.0,\n",
    "    sr=16000,\n",
    "    window_size=20,\n",
    "    stride=10,\n",
    "    n_mels=80,\n",
    "    save_result_every=1000,\n",
    "    save_model_every=10000,\n",
    "    print_every=10,\n",
    "    seed=1,\n",
    "    max_len=151,\n",
    "    load_model=False,\n",
    "    model_path=None\n",
    ")\n",
    "\n",
    "listener = Listener(\n",
    "    in_features=80,\n",
    "    hidden_dim=config.hidden_dim,\n",
    "    dropout_p=config.dropout,\n",
    "    num_layers=config.listener_layer_size,\n",
    "    bidirectional=config.use_bidirectional,\n",
    "    rnn_type='gru',\n",
    "    device='cpu'\n",
    ")\n",
    "speller = Speller(\n",
    "    num_class=2040,\n",
    "    max_length=config.max_len,\n",
    "    k=8,\n",
    "    hidden_dim=config.hidden_dim << (1 if config.use_bidirectional else 0),\n",
    "    sos_id=2037,\n",
    "    eos_id=2038,\n",
    "    num_head=config.num_head,\n",
    "    num_layers=config.speller_layer_size,\n",
    "    rnn_type='gru',\n",
    "    dropout_p=config.dropout,\n",
    "    attn_dim=config.attn_dim\n",
    ")\n",
    "model = ListenAttendSpell(listener, speller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListenAttendSpell(\n",
       "  (listener): Listener(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (rnn): GRU(2560, 256, num_layers=5, batch_first=True, dropout=0.4, bidirectional=True)\n",
       "  )\n",
       "  (speller): Speller(\n",
       "    (rnn): GRU(512, 512, num_layers=3, batch_first=True, dropout=0.4)\n",
       "    (embedding): Embedding(2040, 512)\n",
       "    (input_dropout): Dropout(p=0.4, inplace=False)\n",
       "    (fc): Linear(in_features=512, out_features=2040, bias=True)\n",
       "    (attention): MultiHeadAttention(\n",
       "      (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (fc): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_length = 120\n",
    "feature_size = 80\n",
    "max_length = 150\n",
    "\n",
    "inputs = torch.zeros((batch_size, seq_length, feature_size))\n",
    "scripts = torch.zeros((batch_size, seq_length, max_length), dtype=torch.long)\n",
    "summary(model, inputs, scripts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
